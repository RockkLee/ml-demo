{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# batch & time & channel\n",
    "In the context of transformer models, the terms \"batch,\" \"time,\" and \"channel\" refer to different dimensions of the input data. Here's a breakdown of each term:\n",
    "- **Batch**: The number of sentences (or sequences) processed at the same time.\n",
    "- **Time**: The number of tokens in each sentence (or the length of the sequence).\n",
    "- **Channel**: The size of the embedding for each token.\n",
    "\n",
    "So, an input tensor to a transformer model might have the shape `[batch_size, sequence_length, embedding_size]`. \n",
    "For example, if you have a batch of **32 sentences**, each with **50 tokens**, and **each token is represented by a 512-dimensional embedding**, the input tensor shape would be `[32, 50, 512]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      " ['Never', 'gonna', 'give', 'you', 'up', 'Never', 'gonna', 'let', 'you', 'down', 'Never', 'gonna', 'run', 'around', 'and', 'desert', 'you', 'Never', 'gonna', 'make', 'you', 'cry', 'Never', 'gonna', 'say', 'goodbye', 'Never', 'gonna', 'tell', 'a', 'lie', 'and', 'hurt', 'you']\n",
      "Token to Integer Mapping:\n",
      " {'run': 1, 'and': 2, 'goodbye': 3, 'up': 4, 'let': 5, 'tell': 6, 'a': 7, 'around': 8, 'gonna': 9, 'cry': 10, 'hurt': 11, 'lie': 12, 'desert': 13, 'say': 14, 'down': 15, 'make': 16, 'give': 17, 'you': 18, 'Never': 19}\n",
      "Integer to Token Mapping:\n",
      " {1: 'run', 2: 'and', 3: 'goodbye', 4: 'up', 5: 'let', 6: 'tell', 7: 'a', 8: 'around', 9: 'gonna', 10: 'cry', 11: 'hurt', 12: 'lie', 13: 'desert', 14: 'say', 15: 'down', 16: 'make', 17: 'give', 18: 'you', 19: 'Never', 0: '<pad>'}\n",
      "Encoded Lyrics:\n",
      " [19, 9, 17, 18, 4, 19, 9, 5, 18, 15, 19, 9, 1, 8, 2, 13, 18, 19, 9, 16, 18, 10, 19, 9, 14, 3, 19, 9, 6, 7, 12, 2, 11, 18]\n"
     ]
    }
   ],
   "source": [
    "# Lyrics of \"Never Gonna Give You Up\"\n",
    "lyrics = \"\"\"Never gonna give you up\n",
    "Never gonna let you down\n",
    "Never gonna run around and desert you\n",
    "Never gonna make you cry\n",
    "Never gonna say goodbye\n",
    "Never gonna tell a lie and hurt you\"\"\"\n",
    "\n",
    "# Tokenizing the lyrics\n",
    "tokens = lyrics.split()\n",
    "print(\"Tokens:\\n\", tokens)\n",
    "\n",
    "# Create a mapping from tokens to integers\n",
    "token_to_int = {token: idx for idx, token in enumerate(set(tokens), 1)}\n",
    "int_to_token = {idx: token for token, idx in token_to_int.items()}\n",
    "int_to_token[0] = \"<pad>\"\n",
    "print(\"Token to Integer Mapping:\\n\", token_to_int)\n",
    "print(\"Integer to Token Mapping:\\n\", int_to_token)\n",
    "\n",
    "# Convert tokens to integers\n",
    "encoded_lyrics = [token_to_int[token] for token in tokens]\n",
    "\n",
    "# Display the token to integer mapping and encoded lyrics\n",
    "print(\"Encoded Lyrics:\\n\", encoded_lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple transformer model\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, embedding_size, num_heads, num_layers, vocab_size):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=embedding_size,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.linear = nn.Linear(embedding_size, vocab_size)\n",
    "    \n",
    "    def forward(self, src, tgt):\n",
    "        src_emb = self.embedding(src)\n",
    "        tgt_emb = self.embedding(tgt)\n",
    "        transformer_output = self.transformer(src_emb, tgt_emb)\n",
    "        output = self.linear(transformer_output)\n",
    "        return output\n",
    "\n",
    "    def generate(self, src, max_length):\n",
    "        src_emb = self.embedding(src)\n",
    "        memory = self.transformer.encoder(src_emb)\n",
    "        ys = torch.zeros(1, 1).type_as(src.data)\n",
    "\n",
    "        for i in range(max_length-1):\n",
    "            tgt_emb = self.embedding(ys)\n",
    "            out = self.transformer.decoder(tgt_emb, memory)\n",
    "            out = self.linear(out)\n",
    "            prob = out[:, -1, :].squeeze().softmax(dim=-1)\n",
    "            next_word = torch.argmax(prob).item()\n",
    "            ys = torch.cat([ys, torch.tensor([[next_word]]).type_as(src.data)], dim=1)\n",
    "            if next_word == token_to_int.get('<eos>', 0):  # Assuming <eos> token for end of sentence\n",
    "                break\n",
    "        return ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: torch.Size([1, 34, 512])\n",
      "Input data:\n",
      " tensor([[[19., 19., 19.,  ..., 19., 19., 19.],\n",
      "         [ 9.,  9.,  9.,  ...,  9.,  9.,  9.],\n",
      "         [17., 17., 17.,  ..., 17., 17., 17.],\n",
      "         ...,\n",
      "         [ 2.,  2.,  2.,  ...,  2.,  2.,  2.],\n",
      "         [11., 11., 11.,  ..., 11., 11., 11.],\n",
      "         [18., 18., 18.,  ..., 18., 18., 18.]]])\n",
      "Source shape: torch.Size([34, 1, 512])\n",
      "Target shape: torch.Size([34, 1, 512])\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "batch_size = 1  # For simplicity, using a batch size of 1\n",
    "sequence_length = len(encoded_lyrics)\n",
    "embedding_size = 512\n",
    "\n",
    "# Simulate embedding by creating a tensor with random values\n",
    "# Normally, you would use actual embeddings here\n",
    "input_data = (torch.tensor(encoded_lyrics) # 1 x 34\n",
    "    .view(batch_size, sequence_length, 1) # 1 x 34 x 1\n",
    "    .float()\n",
    "    .repeat(1, 1, embedding_size)) # 1 x 34 x 512\n",
    "print(\"Input data shape:\", input_data.shape)\n",
    "print(\"Input data:\\n\", input_data)\n",
    "\n",
    "# Permute to match transformer input shape [sequence_length, batch_size, embedding_size]\n",
    "# permute() returns a view of the input tensor with dimensions permuted(變更/交換).\n",
    "src = input_data.permute(1, 0, 2) # 1 x 34 x 512 -> 34 x 1 x 512\n",
    "tgt = input_data.permute(1, 0, 2)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"Source shape:\", src.shape)\n",
    "print(\"Target shape:\", tgt.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 34, 20])\n",
      "<pad> gonna gonna lie gonna let Never let Never let gonna let gonna gonna gonna down let gonna gonna say \n"
     ]
    }
   ],
   "source": [
    "# Parameters for the transformer\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "vocab_size = len(token_to_int) + 1  # Plus one for padding/indexing\n",
    "\n",
    "# Create the model\n",
    "model = SimpleTransformer(embedding_size, num_heads, num_layers, vocab_size)\n",
    "\n",
    "# Forward pass\n",
    "src = torch.tensor(encoded_lyrics).unsqueeze(0)  # Add batch dimension\n",
    "tgt = torch.tensor(encoded_lyrics).unsqueeze(0)  # Add batch dimension\n",
    "output = model(src, tgt)\n",
    "\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "# Generate new sequence\n",
    "start_token = torch.tensor([[token_to_int[\"Never\"]]])\n",
    "generated_sequence = model.generate(start_token, max_length=20)\n",
    "str_list = list(map(lambda s: int_to_token.get(s)+\" \", generated_sequence[0].tolist()))\n",
    "generated_txt = \"\".join(str_list)\n",
    "print(generated_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
